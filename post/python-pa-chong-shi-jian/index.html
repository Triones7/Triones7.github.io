<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Python爬虫实践 | Gridea</title>
<link rel="shortcut icon" href="https://triones7.github.io/favicon.ico?v=1614960525879">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://triones7.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Python爬虫实践 | Gridea - Atom Feed" href="https://triones7.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="前几天疫情比较严重，设计了一个爬取新闻的爬虫程序，分享一下。
...

概述
主要是平常还挺喜欢澎湃新闻的，就选择爬取了澎湃新闻的主页，还可以，设置了headers之后也没有遇到什么反爬虫机制，还算和平，当然，也遇到了很多问题，我为了自己，..." />
    <meta name="keywords" content="爬虫,编程,分享" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://triones7.github.io">
  <img class="avatar" src="https://triones7.github.io/images/avatar.png?v=1614960525879" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    记录、想法、生活
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/ethanwu7" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
    
      
    
      
        <a href="https://www.zhihu.com/people/triones-53-93" target="_blank">
          <i class="ri-zhihu-line"></i>
        </a>
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Python爬虫实践
            </h2>
            <div class="post-info">
              <span>
                2020-02-10
              </span>
              <span>
                11 min read
              </span>
              
                <a href="https://triones7.github.io/tag/mRkq61yLh/" class="post-tag">
                  # 爬虫
                </a>
              
                <a href="https://triones7.github.io/tag/67sVQGWec/" class="post-tag">
                  # 编程
                </a>
              
                <a href="https://triones7.github.io/tag/2c-P1Ex7yV/" class="post-tag">
                  # 分享
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://triones7.github.io/post-images/python-pa-chong-shi-jian.jpg" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>前几天疫情比较严重，设计了一个爬取新闻的爬虫程序，分享一下。<br>
...</p>
<!-- more -->
<h2 id="概述">概述</h2>
<p>主要是平常还挺喜欢澎湃新闻的，就选择爬取了澎湃新闻的主页，还可以，设置了headers之后也没有遇到什么反爬虫机制，还算和平，当然，也遇到了很多问题，我为了自己，也为了分享，将每一行代码详细的注释都写在旁边，应该有基础就可以看懂。</p>
<h2 id="源代码">源代码</h2>
<p>废话不多说，直接贴代码。</p>
<pre><code class="language-python"># -*-coding:utf-8-*-

from bs4 import BeautifulSoup#导入bs4模块，用BeautifulSoup分析网页
import requests#导入requests模块，用于向服务器发送请求
import os#导入os模块，用于文件处理(未系统学习，参照慎用)
import re#导入re模块，实现正则表达式的使用
import webbrowser#导入webbrowser模块，用于使用用户的默认浏览器打开网页
import time#导入time模块，用于实现程序延迟
import sys#导入sys模块，用于实现程序重启(重启程序楼主在网上找的，也不知道具体用法)

def url_open(url):#使用定义函数
	headers = {}#创建Headers,用于模拟浏览器发送请求
	headers[&quot;Accept&quot;] = &quot;image/webp,image/apng,image/*,*/*;q=0.8&quot;
	headers[&quot;Accept-Encoding&quot;] = &quot;gzip, deflate, br&quot;
	headers[&quot;Accept-Language&quot;] = &quot;zh-CN,zh;q=0.9&quot;
	headers[&quot;User-Agent&quot;] = &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36&quot;
	response = requests.get(url, headers=headers)#用requests模块下的get命令，请求服务器，同时发送headers以模拟浏览器
	response.encoding = &quot;utf-8&quot;#将从服务器获取到的内容转化为utf-8编码

	html = response.text#使用text命令将二进制编码转换为文本

	return html#函数输出命令，输出html

def restart_program():
	print(&quot;restart program&quot;)
	python = sys.executable #获取当前执行python 
	os.execl(python, python, *sys.argv)  #执行命令

print(&quot;本程序使用爬虫爬取，新闻内容来自澎湃新闻。\n&quot;)
time.sleep(1)
print(&quot;本程序读取新闻时会爬取来源，如需转载请注明来源！\n&quot;)
time.sleep(1)
print(&quot;感谢使用本程序，本程序由北斗工作室开发，如需转载或引用，请标注来源！\n\n\n&quot;)
time.sleep(2)

print(&quot;以下是爬取的热点前20新闻：\n&quot;)
time.sleep(1)

base_url = &quot;https://www.thepaper.cn/&quot;#设定主链接变量

web = url_open(base_url)#引用自己编写的函数模块，获取网页html

soup = BeautifulSoup(web, features='lxml')#使用bs4中的BeautifulSoup解析网页，引用lxml格式的解析器
all_h2 = soup.find_all('h2')#找到所有带h2标签的html语言，即澎湃新闻官网的大新闻标题

all_title = []#创建一个新的list
for each_h2 in all_h2:#使用for in循环，逐个去除每一个h2标签下的语言，获得标题
	title = each_h2.get_text()#对每一个标签用Get_text命令获取文本
	all_title.append(title)#将获取到的标题添加到All_title中

price = [x.strip() for x in all_title if x.strip() != '']#引用自网友的命令，去除all_title里的所有换行符

links = re.findall(r&quot;newsDetail_forward_\d{7}&quot;, str(all_h2))#使用正则表达式获取所有标题对应的链接，并返回一个list，注意！正则表达式要求一个str格式！

for m in range(20):#创建一个20次的循环，输出20条新闻
	this_title = price[m]#输出price(去除过换行符后的list)的第m项
	this_link = links[m]#输出links里的第m项
	n = m + 1#创建n,用于标注序号，因为range是从0开始，所以m+1表示序号
	print (n, this_title + &quot;\n&quot;)#输出新闻标题 + 链接
	time.sleep(1)

choice = input(&quot;请输入您感兴趣的新闻序号：&quot;)#请求输入，获得用户所需新闻
num = int(choice) - 1#将输入的str转化为int并进行-1使之转化为list的索引序号
news_link = links[num]#用输入的结果生成的索引，在links这个list里索引对应的网址
news_url = base_url + news_link#将索引到的网址与澎湃官网的base url合并，生成完整的地址

time.sleep(1)
print(&quot;1 使用默认浏览器访问新闻网页\n&quot;)
time.sleep(1)
print(&quot;2 爬取新闻内容并展示\n\n&quot;)#打印出选项，让用户选择进行新闻访问/直接爬取新闻
time.sleep(1)

choice2 = input(&quot;请输入数字选择：&quot;)#使用input函数获取用户选择
a = int(choice2)#将获得的选择转化为int形式，便于使用if else进行比较

if a == 1:#引入if条件判断，判断用户选择是多少
	webbrowser.open(news_url)#使用webbrowser模块，唤起默认浏览器，打开页面
elif a == 2:#再用elif判断
	html2 = url_open(news_url)#用自己定义的url_open函数获得news_url的页面
	soup2 = BeautifulSoup(html2, features='lxml')#使用BeautifulSoup解析新闻页面
	title2 = soup2.find('h1')#找到h1标题
	laiyuan = soup2.find('div', {&quot;class&quot;:&quot;news_about&quot;})#找到class标签为news_about的div标签
	time2 = laiyuan.find_all('p')#找到div标签下的p标签
	v = []#创建一个空的list——v
	for z in time2:#for in 函数输出
		u = z.get_text()#用get_text()命令获得文本
		v.append(u)#将获得的文本添加进v这个list中
	price2 = [y.strip() for y in v if y.strip() != '']#引用自网友的命令，去除all_title里的所有换行符
	news_text = soup2.find('div', {&quot;class&quot;:&quot;news_txt&quot;})#找到网页所有的div标签下class = news_txt的标签
	news_list_dealt = news_text.get_text()#使用get_text命令获得新闻正文
	news_list = list(news_list_dealt)#将新闻正文转化为list
	for i in range(29):#循环29次，用于去除澎湃下载下来自带的广告(字符正好是29个)
		news_list.pop()#使用pop指令去除正文list中的最后一项
	news_str = &quot;&quot;.join(news_list)#引自网友，将list合并为string
	print (&quot;\n\n标题：&quot; + title2.get_text() + &quot;\n\n来源&amp;时间：&quot; + price2[0] + &quot;\n&quot; + price2[1] + &quot;\n\n正文：&quot; + news_str)#输出标题，来源，正文
else:
	print(&quot;请按要求输入文本！&quot;)#使用else判断出用户输入其他字符
	time.sleep(1)
	print(&quot;程序即将重启！请重新选择！&quot;)#告诉用户即将重启
	restart_program()#通过重启模块实现重新选择，偷懒。。。。

print (&quot;\n请选择:\n&quot;)
time.sleep(1)
print(&quot;1 选择另一条新闻\n&quot;)
time.sleep(1)
print(&quot;2 退出程序\n&quot;)
time.sleep(1)
print(&quot;3 关于\n&quot;)
time.sleep(1)
print(&quot;4 在默认浏览器里浏览该新闻\n&quot;)

choice3 = input(&quot;\n请输入数字选项：&quot;)#获得用户选择
b = int(choice3)#将用户的结果转化为整数形式！很重要！input获得的结果是string

if b == 1:#继续判断
	restart_program()#通过重启程序让用户选择另一条新闻，又偷懒。。
elif b == 2:
	print(&quot;感谢使用本程序，欢迎下次使用！&quot;)
	time.sleep(2)#使用time函数，实现程序延迟2秒
	print(&quot;再见，本程序将在3秒后自动退出！&quot;)
	count = 0#从本行到第98行，实现倒计时并倒数
	b = 3
	while (int(count) &lt; int(b)):
		ncount = int(b) - int(count) 
		print (ncount)
		time.sleep(1)
		count += 1 
elif b == 3:
	print(&quot;本程序由北斗工作室开发！\n&quot;)
	time.sleep(1)#使用time函数，实现程序延迟1秒
	print(&quot;Triones Studio .Inc\n&quot;)
	time.sleep(1)#使用time函数，实现程序延迟1秒
	print(&quot;如需搬运，请标注来源！谢谢！\n&quot;)
	time.sleep(1)#使用time函数，实现程序延迟1秒
	print(&quot;本程序作者学习来自莫烦python,主页：https://morvanzhou.github.io/&quot;)
	time.sleep(1)#使用time函数，实现程序延迟1秒
	print(&quot;本程序引用的重启函数，来自博客园网站某博主，感谢！&quot;)
	time.sleep(1)#使用time函数，实现程序延迟1秒
	print(&quot;程序即将重启！请重新选择！&quot;)
	restart_program()#通过重启模块实现重新选择，偷懒。。。。
elif b == 4:
	webbrowser.open(news_url)#使用webbrowser模块，唤起默认浏览器，打开页面
	print (&quot;\n请选择:\n&quot;)
	time.sleep(1)
	print(&quot;1 选择另一条新闻\n&quot;)
	time.sleep(1)
	print(&quot;2 退出程序\n&quot;)
	time.sleep(1)
	print(&quot;3 关于\n&quot;)
	choice3 = input(&quot;\n请输入数字选项：&quot;)#获得用户选择
	c = int(choice3)#将用户的结果转化为整数形式！很重要！input获得的结果是string

	if c == 1:#继续判断
		restart_program()#通过重启程序让用户选择另一条新闻，又偷懒。。
	elif c == 2:
		print(&quot;感谢使用本程序，欢迎下次使用！&quot;)
		time.sleep(2)#使用time函数，实现程序延迟2秒
		print(&quot;再见，本程序将在3秒后自动退出！&quot;)
		count = 0#从本行到第98行，实现倒计时并倒数
		c = 3
		while (int(count) &lt; int(c)):
			ncount = int(c) - int(count) 
			print (ncount)
			time.sleep(1)
			count += 1 
	elif c == 3:
		print(&quot;本程序由北斗工作室开发！\n&quot;)
		time.sleep(1)#使用time函数，实现程序延迟1秒
		print(&quot;Triones Studio .Inc\n&quot;)
		time.sleep(1)#使用time函数，实现程序延迟1秒
		print(&quot;如需搬运，请标注来源！谢谢！\n&quot;)
		time.sleep(1)#使用time函数，实现程序延迟1秒
		print(&quot;本程序作者学习来自莫烦python,主页：https://morvanzhou.github.io/&quot;)
		time.sleep(1)#使用time函数，实现程序延迟1秒
		print(&quot;本程序引用的重启函数，来自博客园网站某博主，感谢！&quot;)
		time.sleep(1)#使用time函数，实现程序延迟1秒
		print(&quot;程序即将重启！请重新选择！&quot;)
		restart_program()#通过重启模块实现重新选择，偷懒。。。。
	else:
		print(&quot;请输入数字1/2/3！谢谢！&quot;)
		time.sleep(1)
		print(&quot;程序即将重启！请重新选择！&quot;)
		restart_program()#通过重启模块实现重新选择，偷懒。。。。
else:
	print(&quot;请输入数字1/2/3！谢谢！&quot;)
	time.sleep(1)
	print(&quot;程序即将重启！请重新选择！&quot;)
	restart_program()#通过重启模块实现重新选择，偷懒。。。。
</code></pre>
<h4 id="下载区">下载区</h4>
<p>源代码解释的应该还是挺详细的，这里贴一下下载地址：<a href="https://github.com/Triones7/Triones-Studio/raw/master/%E6%96%B0%E9%97%BB%E7%88%AC%E5%8F%96%E6%BA%90%E4%BB%A3%E7%A0%81.py">点我下载</a>{: .btn}</p>
<h2 id="最后">最后</h2>
<p>如果有任何疑问，或对代码有任何改进，欢迎<a href="https://triones7.github.io/contact/">联系我</a>{: .btn}</p>
<h5 id="ps">P.S.</h5>
<ul>
<li>本文件纯属博主自己编写</li>
<li>如有雷同，纯属巧合</li>
<li>所有新闻软件输出时均<strong>标注来源</strong>，博主不负法律责任</li>
<li><strong>如需转载，请注明来源！</strong></li>
<li>本网站享有<strong>最终解释权</strong></li>
</ul>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E6%A6%82%E8%BF%B0">概述</a></li>
<li><a href="#%E6%BA%90%E4%BB%A3%E7%A0%81">源代码</a><br>
*
<ul>
<li><a href="#%E4%B8%8B%E8%BD%BD%E5%8C%BA">下载区</a></li>
</ul>
</li>
<li><a href="#%E6%9C%80%E5%90%8E">最后</a><br>
*<br>
*<br>
* <a href="#ps">P.S.</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://triones7.github.io/post/about/">
              <h3 class="post-title">
                关于
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://triones7.github.io" target="_blank"> Ethan wu</a>
  <a class="rss" href="https://triones7.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
